{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBoEJLNUY0EJ"
      },
      "source": [
        "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ‚≠ê <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠ê\n",
        "</div>\n",
        "\n",
        "To install Unsloth your local device, follow [our guide](https://docs.unsloth.ai/get-started/install-and-update). This notebook is licensed [LGPL-3.0](https://github.com/unslothai/notebooks?tab=LGPL-3.0-1-ov-file#readme).\n",
        "\n",
        "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkLG6TLp-KUt"
      },
      "source": [
        "### News"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4SIxudc-KUt"
      },
      "source": [
        "\n",
        "Introducing FP8 precision training for faster RL inference. [Read Blog](https://docs.unsloth.ai/new/fp8-reinforcement-learning).\n",
        "\n",
        "Unsloth's [Docker image](https://hub.docker.com/r/unsloth/unsloth) is here! Start training with no setup & environment issues. [Read our Guide](https://docs.unsloth.ai/new/how-to-train-llms-with-unsloth-and-docker).\n",
        "\n",
        "[gpt-oss RL](https://docs.unsloth.ai/new/gpt-oss-reinforcement-learning) is now supported with the fastest inference & lowest VRAM. Try our [new notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/gpt-oss-(20B)-GRPO.ipynb) which creates kernels!\n",
        "\n",
        "Introducing [Vision](https://docs.unsloth.ai/new/vision-reinforcement-learning-vlm-rl) and [Standby](https://docs.unsloth.ai/basics/memory-efficient-rl) for RL! Train Qwen, Gemma etc. VLMs with GSPO - even faster with less VRAM.\n",
        "\n",
        "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edPZXqH6-KUu"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KNHb8EVscjdi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5adb2da-e5c1-41a9-c1f7-3a692b559ed8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'doctors-handwritten-prescription-bd-dataset' dataset.\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"mamun1113/doctors-handwritten-prescription-bd-dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "05Y0VKOH-KUu"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os, re\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    import torch; v = re.match(r\"[0-9]{1,}\\.[0-9]{1,}\", str(torch.__version__)).group(0)\n",
        "    xformers = \"xformers==\" + (\"0.0.33.post1\" if v==\"2.9\" else \"0.0.32.post2\" if v==\"2.8\" else \"0.0.29.post3\")\n",
        "    !pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets==4.3.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
        "    !pip install --no-deps unsloth\n",
        "!pip install transformers==4.56.2\n",
        "!pip install --no-deps trl==0.22.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xLDGk41C7IF"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmUBVEnvCDJv",
        "outputId": "6fd00662-6aed-4251-db7f-1ca987efbf80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
            "Unsloth: WARNING `trust_remote_code` is True.\n",
            "Are you certain you want to do remote code execution?\n",
            "==((====))==  Unsloth 2025.12.8: Fast Paddleocr_Vl patching. Transformers: 4.56.2.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.5.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post1. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: Float16 full finetuning uses more memory since we upcast weights to float32.\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastVisionModel # FastLanguageModel for LLMs\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM ,AutoProcessor\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/Qwen3-VL-8B-Instruct-bnb-4bit\", # Qwen 3 vision support\n",
        "    \"unsloth/Qwen3-VL-8B-Thinking-bnb-4bit\",\n",
        "    \"unsloth/Qwen3-VL-32B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Qwen3-VL-32B-Thinking-bnb-4bit\",\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model_path = \"unsloth/PaddleOCR-VL\"\n",
        "model, tokenizer = FastVisionModel.from_pretrained(\n",
        "    model_path,\n",
        "    max_seq_length = 1024, # Choose any for long context!\n",
        "    load_in_4bit = False,     # 4bit uses much less memory\n",
        "    load_in_8bit = False,    # A bit more accurate, uses 2x memory\n",
        "    full_finetuning=True, # We support full finetuning now!\n",
        "    auto_model=AutoModelForCausalLM,\n",
        "    trust_remote_code = True,\n",
        "    unsloth_force_compile = True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5xLHboFaBd7"
      },
      "source": [
        "We now load the processor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XXlUyieNaA7X"
      },
      "outputs": [],
      "source": [
        "processor = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd9bTZd1aaL"
      },
      "source": [
        "We now add LoRA adapters for parameter efficient finetuning - this allows us to only efficiently train 1% of all parameters.\n",
        "\n",
        "**[NEW]** We also support finetuning ONLY the vision part of the model, or ONLY the language part. Or you can select both! You can also select to finetune the attention or the MLP layers!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bZsfBuZDeCL",
        "outputId": "7ac7afee-f076-4e64-f75b-727c8961509c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Full finetuning is enabled, so .get_peft_model has no effect\n"
          ]
        }
      ],
      "source": [
        "model = FastVisionModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16,\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,\n",
        "    target_modules = [\n",
        "      \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "\n",
        "\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import io\n",
        "from datasets import Dataset\n",
        "\n",
        "# Define your paths\n",
        "CSV_PATH = os.path.join(path, \"Doctor‚Äôs Handwritten Prescription BD dataset/Training/training_labels.csv\")\n",
        "IMAGES_FOLDER = os.path.join(path, \"Doctor‚Äôs Handwritten Prescription BD dataset/Training/training_words\")\n",
        "\n",
        "def load_custom_data(csv_path, images_folder):\n",
        "    df = pd.read_csv(csv_path, header=None)\n",
        "    formatted_data = []\n",
        "    print(f\"Loading data from {csv_path}...\")\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        img_name = str(row[0])\n",
        "        ground_truth = str(row[1])\n",
        "        img_full_path = os.path.join(images_folder, img_name)\n",
        "        try:\n",
        "            image = Image.open(img_full_path).convert(\"RGB\")\n",
        "            formatted_data.append({\"image\": image, \"text\": ground_truth})\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error loading image {img_name}: {e}\")\n",
        "            continue\n",
        "    return formatted_data\n",
        "\n",
        "# 1. Load Data\n",
        "custom_raw_data = load_custom_data(CSV_PATH, IMAGES_FOLDER)\n",
        "\n",
        "# 2. Convert to list format\n",
        "instruction = \"OCR:\"\n",
        "converted_dataset = []\n",
        "\n",
        "for sample in custom_raw_data:\n",
        "    conversation = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                # Text First, then Image\n",
        "                {\"type\": \"text\", \"text\": instruction},\n",
        "                {\"type\": \"image\", \"image\": sample[\"image\"]}\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": sample[\"text\"]}\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "    converted_dataset.append({ \"images\": [sample[\"image\"]], \"messages\": conversation })\n",
        "\n",
        "# 3. Create Dataset\n",
        "hf_dataset = Dataset.from_list(converted_dataset)\n",
        "\n",
        "# 4. === THE CORRECTED TRANSFORM ===\n",
        "def format_output(batch):\n",
        "    formatted_batch = {\"images\": [], \"messages\": []}\n",
        "\n",
        "    for i in range(len(batch[\"images\"])):\n",
        "        # -- Step A: Prepare Master Image --\n",
        "        raw_imgs = batch[\"images\"][i]\n",
        "        valid_images = []\n",
        "        for img in raw_imgs:\n",
        "            if isinstance(img, dict) and \"bytes\" in img:\n",
        "                valid_images.append(Image.open(io.BytesIO(img[\"bytes\"])).convert(\"RGB\"))\n",
        "            else:\n",
        "                valid_images.append(img)\n",
        "\n",
        "        formatted_batch[\"images\"].append(valid_images)\n",
        "        master_image = valid_images[0]\n",
        "\n",
        "        # -- Step B: Fix Messages --\n",
        "        raw_msgs = batch[\"messages\"][i]\n",
        "        clean_msgs = []\n",
        "\n",
        "        for msg in raw_msgs:\n",
        "            new_content = []\n",
        "            for item in msg[\"content\"]:\n",
        "                # FIX: Check if image is present AND NOT NONE\n",
        "                # The library inserts \"image\": None for text items, so we must check values.\n",
        "                if \"image\" in item and item[\"image\"] is not None:\n",
        "                    new_content.append({\"type\": \"image\", \"image\": master_image})\n",
        "                else:\n",
        "                    # It's a text item. Clean up the None keys.\n",
        "                    clean_item = {k: v for k, v in item.items() if v is not None}\n",
        "                    new_content.append(clean_item)\n",
        "\n",
        "            clean_msgs.append({\"role\": msg[\"role\"], \"content\": new_content})\n",
        "\n",
        "        formatted_batch[\"messages\"].append(clean_msgs)\n",
        "\n",
        "    return formatted_batch\n",
        "\n",
        "# Apply the transform\n",
        "hf_dataset.set_transform(format_output)\n",
        "\n",
        "# 5. Split\n",
        "dataset_split = hf_dataset.train_test_split(test_size=0.1)\n",
        "train_dataset = dataset_split[\"train\"]\n",
        "eval_dataset = dataset_split[\"test\"]\n",
        "\n",
        "# === VERIFY OUTPUT ===\n",
        "print(\"\\nSample Output Structure:\")\n",
        "sample = train_dataset[0]\n",
        "\n",
        "# Standard print allows you to see the true structure\n",
        "print(sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CERWDO1elNp",
        "outputId": "75082455-b772-4cd6-a849-8aba6aad96a9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from /kaggle/input/doctors-handwritten-prescription-bd-dataset/Doctor‚Äôs Handwritten Prescription BD dataset/Training/training_labels.csv...\n",
            "‚ö†Ô∏è Error loading image IMAGE: [Errno 2] No such file or directory: '/kaggle/input/doctors-handwritten-prescription-bd-dataset/Doctor‚Äôs Handwritten Prescription BD dataset/Training/training_words/IMAGE'\n",
            "\n",
            "Sample Output Structure:\n",
            "{'images': [<PIL.PngImagePlugin.PngImageFile image mode=RGB size=116x46 at 0x7A66B6C8BE00>], 'messages': [{'role': 'user', 'content': [{'text': 'OCR:', 'type': 'text'}, {'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=116x46 at 0x7A66B6C8BE00>}]}, {'role': 'assistant', 'content': [{'text': 'Opton', 'type': 'text'}]}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vITh0KVJ10qX"
      },
      "source": [
        "<a name=\"Data\"></a>\n",
        "### Data Prep\n",
        "We'll be using a sampled dataset of handwritten maths formulas. The goal is to convert these images into a computer readable form - ie in LaTeX form, so we can render it. This can be very useful for complex formulas.\n",
        "\n",
        "You can access the dataset [here](https://huggingface.co/datasets/unsloth/LaTeX_OCR). The full dataset is [here](https://huggingface.co/datasets/linxy/LaTeX_OCR)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAeQ9LXCAEkW"
      },
      "source": [
        "We can also render the LaTeX in the browser directly!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9CBpiISFa6C"
      },
      "source": [
        "To format the dataset, all vision finetuning tasks should be formatted as follows:\n",
        "\n",
        "```python\n",
        "[\n",
        "{ \"role\": \"user\",\n",
        "  \"content\": [{\"type\": \"text\",  \"text\": Q}, {\"type\": \"image\", \"image\": image} ]\n",
        "},\n",
        "{ \"role\": \"assistant\",\n",
        "  \"content\": [{\"type\": \"text\",  \"text\": A} ]\n",
        "},\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FY-9u-OD6_gE"
      },
      "source": [
        "Let's convert the dataset into the \"correct\" format for finetuning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcYcVH3MdaXg",
        "outputId": "7321cfb7-183d-4a4c-b2ca-e62d2df8b22d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from /kaggle/input/doctors-handwritten-prescription-bd-dataset/Doctor‚Äôs Handwritten Prescription BD dataset/Training/training_labels.csv...\n",
            "‚ö†Ô∏è Error loading image IMAGE: [Errno 2] No such file or directory: '/kaggle/input/doctors-handwritten-prescription-bd-dataset/Doctor‚Äôs Handwritten Prescription BD dataset/Training/training_words/IMAGE'\n",
            "Data Prep Complete!\n",
            "\n",
            "Sample Output Structure:\n",
            "{'images': [<PIL.PngImagePlugin.PngImageFile image mode=RGB size=89x38 at 0x7A66B7C69B80>],\n",
            " 'messages': [{'content': [{'text': 'Read the handwritten medical term.',\n",
            "                            'type': 'text'},\n",
            "                           {'image': <PIL.Image.Image image mode=RGB size=89x38 at 0x7A66B7C6A660>,\n",
            "                            'type': 'image'}],\n",
            "               'role': 'user'},\n",
            "              {'content': [{'text': 'Fexofast', 'type': 'text'}],\n",
            "               'role': 'assistant'}]}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import io\n",
        "from datasets import Dataset\n",
        "\n",
        "# Define your paths\n",
        "CSV_PATH = os.path.join(path, \"Doctor‚Äôs Handwritten Prescription BD dataset/Training/training_labels.csv\")      # Update this path\n",
        "IMAGES_FOLDER = os.path.join(path, \"Doctor‚Äôs Handwritten Prescription BD dataset/Training/training_words\")\n",
        "\n",
        "\n",
        "\n",
        "def load_custom_data(csv_path, images_folder):\n",
        "    df = pd.read_csv(csv_path, header=None)\n",
        "    formatted_data = []\n",
        "    print(f\"Loading data from {csv_path}...\")\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        img_name = str(row[0])\n",
        "        ground_truth = str(row[1])\n",
        "        img_full_path = os.path.join(images_folder, img_name)\n",
        "        try:\n",
        "            image = Image.open(img_full_path).convert(\"RGB\")\n",
        "            formatted_data.append({\"image\": image, \"text\": ground_truth})\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error loading image {img_name}: {e}\")\n",
        "            continue\n",
        "    return formatted_data\n",
        "\n",
        "# 1. Load Data\n",
        "custom_raw_data = load_custom_data(CSV_PATH, IMAGES_FOLDER)\n",
        "\n",
        "# 2. Convert to list format\n",
        "instruction = \"Read the handwritten medical term.\"\n",
        "converted_dataset = []\n",
        "\n",
        "for sample in custom_raw_data:\n",
        "    # We create the structure with specific keys here\n",
        "    # Arrow will technically fill missing ones with nulls internally,\n",
        "    # but our transform below will remove them.\n",
        "    conversation = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": instruction},\n",
        "                {\"type\": \"image\", \"image\": sample[\"image\"]}\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": sample[\"text\"]}\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "    converted_dataset.append({ \"images\": [sample[\"image\"]], \"messages\": conversation })\n",
        "\n",
        "# 3. Create Dataset\n",
        "hf_dataset = Dataset.from_list(converted_dataset)\n",
        "\n",
        "# 4. === THE CLEANING TRANSFORM ===\n",
        "# This function does two things:\n",
        "# a) Converts bytes back to PIL Images\n",
        "# b) Removes any key that is None (cleaning the schema)\n",
        "def format_output(batch):\n",
        "    formatted_batch = {\"images\": [], \"messages\": []}\n",
        "\n",
        "    for i in range(len(batch[\"images\"])):\n",
        "        # -- Handle Top-Level Images --\n",
        "        raw_imgs = batch[\"images\"][i]\n",
        "        processed_imgs = []\n",
        "        for img in raw_imgs:\n",
        "            if isinstance(img, dict) and \"bytes\" in img:\n",
        "                processed_imgs.append(Image.open(io.BytesIO(img[\"bytes\"])).convert(\"RGB\"))\n",
        "            else:\n",
        "                processed_imgs.append(img)\n",
        "        formatted_batch[\"images\"].append(processed_imgs)\n",
        "\n",
        "        # -- Handle Messages (The Clean-up) --\n",
        "        raw_msgs = batch[\"messages\"][i]\n",
        "        clean_msgs = []\n",
        "        for msg in raw_msgs:\n",
        "            clean_content = []\n",
        "            for item in msg[\"content\"]:\n",
        "                # Create a new dictionary excluding any None values\n",
        "                clean_item = {}\n",
        "                for k, v in item.items():\n",
        "                    if v is not None:\n",
        "                        # Decode image if present\n",
        "                        if k == \"image\" and isinstance(v, dict) and \"bytes\" in v:\n",
        "                            clean_item[k] = Image.open(io.BytesIO(v[\"bytes\"])).convert(\"RGB\")\n",
        "                        else:\n",
        "                            clean_item[k] = v\n",
        "                clean_content.append(clean_item)\n",
        "            clean_msgs.append({\"role\": msg[\"role\"], \"content\": clean_content})\n",
        "\n",
        "        formatted_batch[\"messages\"].append(clean_msgs)\n",
        "\n",
        "    return formatted_batch\n",
        "\n",
        "# Apply the cleaning transform\n",
        "hf_dataset.set_transform(format_output)\n",
        "\n",
        "# 5. Split\n",
        "dataset_split = hf_dataset.train_test_split(test_size=0.1)\n",
        "train_dataset = dataset_split[\"train\"]\n",
        "eval_dataset = dataset_split[\"test\"]\n",
        "\n",
        "print(\"Data Prep Complete!\")\n",
        "\n",
        "# === VERIFY OUTPUT ===\n",
        "print(\"\\nSample Output Structure:\")\n",
        "sample = train_dataset[0]\n",
        "\n",
        "# This print ensures the structure is exactly what you asked for\n",
        "import pprint\n",
        "pprint.pprint(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndDUB23CGAC5"
      },
      "source": [
        "We look at how the conversations are structured for the first example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTlOMagwZo6z",
        "outputId": "7103fc25-4bb3-469b-cf72-3b723c0c0ced"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'images': [<PIL.PngImagePlugin.PngImageFile image mode=RGB size=150x38>],\n",
              " 'messages': [{'role': 'user',\n",
              "   'content': [{'text': 'Read the handwritten medical term.', 'type': 'text'},\n",
              "    {'image': <PIL.Image.Image image mode=RGB size=150x38>, 'type': 'image'}]},\n",
              "  {'role': 'assistant', 'content': [{'text': 'Metro', 'type': 'text'}]}]}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "train_dataset[50]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FecKS-dA82f5"
      },
      "source": [
        "Let's first see before we do any finetuning what the model outputs for the first example!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextStreamer\n",
        "def run_inference(idx):\n",
        "    # 1. Setup Data\n",
        "    # CHANGED: \"image\" -> \"images\"[0]\n",
        "    image = train_dataset[idx][\"images\"][0]\n",
        "\n",
        "    ground_truth = train_dataset[idx][\"messages\"][1][\"content\"][0][\"text\"]\n",
        "    instruction = \"OCR:\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": [\n",
        "            {\"type\": \"image\"},\n",
        "            {\"type\": \"text\", \"text\": instruction}\n",
        "        ]}\n",
        "    ]\n",
        "\n",
        "    # 2. Prepare Inputs\n",
        "    text_prompt = processor.tokenizer.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "    inputs = processor(\n",
        "        image, text_prompt, add_special_tokens=False, return_tensors=\"pt\"\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    # 3. Generate\n",
        "    print(f\"\\n--- Index {idx} ---\")\n",
        "    print(f\"Ground Truth: {ground_truth}\")\n",
        "    print(\"Prediction: \", end=\"\")\n",
        "\n",
        "    streamer = TextStreamer(processor.tokenizer, skip_prompt=True)\n",
        "    _ = model.generate(\n",
        "        **inputs,\n",
        "        streamer=streamer,\n",
        "        max_new_tokens=128,\n",
        "        use_cache=False,\n",
        "        temperature=1.5,\n",
        "        min_p=0.1\n",
        "    )\n",
        "\n",
        "# Try running it now\n",
        "run_inference(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcyh7Teim7NS",
        "outputId": "ee4f4ec8-5986-46e4-e789-cf39f19c7bd6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Index 0 ---\n",
            "Ground Truth: Fexofast\n",
            "Prediction: fexoFast</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxrMF3d3l312",
        "outputId": "4e510875-b15a-4fe9-9d74-baa19f6ad45a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from jiwer) (8.3.1)\n",
            "Requirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.12/dist-packages (from jiwer) (3.14.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "from jiwer import cer\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. Setup Selection\n",
        "num_samples = 10\n",
        "if len(train_dataset) < num_samples:\n",
        "    num_samples = len(train_dataset)\n",
        "\n",
        "indices = random.sample(range(len(train_dataset)), num_samples)\n",
        "\n",
        "predictions = []\n",
        "references = []\n",
        "\n",
        "print(f\"Starting inference on {num_samples} random samples...\")\n",
        "\n",
        "# 2. Loop through samples\n",
        "for idx in tqdm(indices):\n",
        "    image = train_dataset[idx][\"images\"][0]\n",
        "    ground_truth = train_dataset[idx][\"messages\"][1][\"content\"][0][\"text\"]\n",
        "    instruction = \"OCR:\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": [\n",
        "            {\"type\": \"image\"},\n",
        "            {\"type\": \"text\", \"text\": instruction}\n",
        "        ]}\n",
        "    ]\n",
        "\n",
        "    text_prompt = processor.tokenizer.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    inputs = processor(\n",
        "        image, text_prompt, add_special_tokens=False, return_tensors=\"pt\"\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    # Generate\n",
        "    with torch.inference_mode():\n",
        "        output_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=128,\n",
        "            use_cache=False,  # <--- CHANGED THIS TO FALSE\n",
        "            temperature=1.5,\n",
        "            min_p=0.1\n",
        "        )\n",
        "\n",
        "    # Decode Output\n",
        "    input_length = inputs.input_ids.shape[1]\n",
        "    generated_ids = output_ids[:, input_length:]\n",
        "    pred_text = processor.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    predictions.append(pred_text)\n",
        "    references.append(ground_truth)\n",
        "\n",
        "# 3. Calculate CER\n",
        "score = cer(references, predictions)\n",
        "print(f\"\\nResults over {num_samples} samples:\")\n",
        "print(f\"Average CER: {score:.4f} (Lower is better)\")\n",
        "print(f\"Percentage Accuracy: {(1-score)*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCOCUw8ymoua",
        "outputId": "63b70dba-9535-409f-f33a-45b3595ce07b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting inference on 10 random samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|‚ñà‚ñà        | 2/10 [00:01<00:04,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "smart_resize: height=26 < factor=28, reset height=factor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:05<00:00,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results over 10 samples:\n",
            "Average CER: 0.3099 (Lower is better)\n",
            "Percentage Accuracy: 69.01%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idAEIeSQ3xdS"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "Now let's train our model. We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!\n",
        "\n",
        "We use our new `UnslothVisionDataCollator` which will help in our vision finetuning setup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "95_Nn-89DhsL"
      },
      "outputs": [],
      "source": [
        "from trl import SFTTrainer, SFTConfig\n",
        "from unsloth.trainer import UnslothVisionDataCollator\n",
        "\n",
        "FastVisionModel.for_training(model) # Enable for training!\n",
        "\n",
        "custom_collator = UnslothVisionDataCollator(\n",
        "    model=model,\n",
        "    processor=processor,\n",
        "    ignore_index=-100,\n",
        "    max_seq_length=1024,\n",
        "    train_on_responses_only=True,\n",
        "    instruction_part = \"User: \",\n",
        "    response_part = \"\\nAssistant:\",\n",
        "    pad_to_multiple_of = 8,\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = processor.tokenizer,\n",
        "    data_collator = custom_collator,\n",
        "    train_dataset = train_dataset,\n",
        "    args = SFTConfig(\n",
        "        per_device_train_batch_size = 4,\n",
        "        gradient_accumulation_steps = 2, # Use GA to mimic batch size!\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 300,\n",
        "        # num_train_epochs = 1, # Set this instead of max_steps for full training runs\n",
        "        learning_rate = 5e-6,\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.001,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"none\",\n",
        "\n",
        "        # You MUST put the below items for vision finetuning:\n",
        "        remove_unused_columns = False,\n",
        "        dataset_text_field = \"\",\n",
        "        dataset_kwargs = {\"skip_prepare_dataset\": True},\n",
        "        max_length = 1024,\n",
        "        fp16 = not torch.cuda.is_bf16_supported(),\n",
        "        bf16 = torch.cuda.is_bf16_supported(),\n",
        "    ),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ejIt2xSNKKp",
        "outputId": "b656d975-a1db-4e00-8ced-969702a36bc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU = Tesla T4. Max memory = 14.741 GB.\n",
            "5.266 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "# @title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yqxqAZ7KJ4oL",
        "outputId": "c7727fcc-08fa-402c-d0dc-daedcf3ca4ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 2,808 | Num Epochs = 1 | Total steps = 300\n",
            "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 2\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 2 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 958,588,736 of 958,588,736 (100.00% trained)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 33:26, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>18.428400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>15.542200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>17.584400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>18.438900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>17.059700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>15.296500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>16.372400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>16.577700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>12.938400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>14.058000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>9.867000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>9.466400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>9.692300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>8.447300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>8.199700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>9.127900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>7.779100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>7.980500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>8.902700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>5.390800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>7.695600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>7.219600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>6.669000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>5.898000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>6.157700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>5.347900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>5.235300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>5.708000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>4.431900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>4.779200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>7.606800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>5.283000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>7.418000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>5.154700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>4.863000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>4.115500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>5.908900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>4.533200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>5.192000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>5.176200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>4.004400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>3.050100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>3.981000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.940300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>3.210600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>2.631800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>2.868100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>2.172000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>2.882100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>5.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>3.346800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>2.527600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>2.037600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>2.360500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>2.368800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>3.065200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>2.171600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>2.476100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>3.030000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>2.864400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>2.201700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>2.519200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>2.382900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>1.616300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>3.004400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.977000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>1.863600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>1.858200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>1.487800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.059200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>3.515300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>2.081700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>2.021900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>2.136600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>1.936600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>1.581700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>1.753100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>2.425000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>1.441600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.313000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>1.911500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>1.675900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>1.943900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>2.339000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>1.152200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>1.031100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>1.593500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.669800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>1.103000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.860700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>2.241900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.742200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>1.858800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>1.325600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>1.052600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>1.391400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.953400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.901300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>1.121200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.214500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>101</td>\n",
              "      <td>1.029500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>102</td>\n",
              "      <td>1.164700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>103</td>\n",
              "      <td>1.523500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>104</td>\n",
              "      <td>0.770900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>0.932500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>106</td>\n",
              "      <td>1.705900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>107</td>\n",
              "      <td>0.541500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>0.579100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>109</td>\n",
              "      <td>0.579100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.439500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>111</td>\n",
              "      <td>1.193700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>112</td>\n",
              "      <td>2.117600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>113</td>\n",
              "      <td>1.139000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>114</td>\n",
              "      <td>0.746200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>0.696400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>116</td>\n",
              "      <td>0.532200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>117</td>\n",
              "      <td>0.291900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>118</td>\n",
              "      <td>0.679400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>119</td>\n",
              "      <td>0.218600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.186000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>121</td>\n",
              "      <td>0.658800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>122</td>\n",
              "      <td>0.779200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>123</td>\n",
              "      <td>0.756700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>124</td>\n",
              "      <td>1.129000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>2.760400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>126</td>\n",
              "      <td>1.524700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>127</td>\n",
              "      <td>1.337300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>128</td>\n",
              "      <td>1.407300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>129</td>\n",
              "      <td>1.996100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.393000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>131</td>\n",
              "      <td>0.724800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>132</td>\n",
              "      <td>2.118900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>133</td>\n",
              "      <td>1.341800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>134</td>\n",
              "      <td>0.730000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>1.136600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>136</td>\n",
              "      <td>0.201100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>137</td>\n",
              "      <td>1.269000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>138</td>\n",
              "      <td>0.402500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>139</td>\n",
              "      <td>0.877100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.554800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>141</td>\n",
              "      <td>0.368000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>142</td>\n",
              "      <td>0.667200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>143</td>\n",
              "      <td>0.826800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>144</td>\n",
              "      <td>0.916700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>145</td>\n",
              "      <td>0.476500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>146</td>\n",
              "      <td>0.623400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>147</td>\n",
              "      <td>0.538800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>148</td>\n",
              "      <td>0.926700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>149</td>\n",
              "      <td>1.052500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.660100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>151</td>\n",
              "      <td>0.320000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>152</td>\n",
              "      <td>0.243500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>153</td>\n",
              "      <td>0.670700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>154</td>\n",
              "      <td>0.455500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>155</td>\n",
              "      <td>0.129400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>156</td>\n",
              "      <td>0.296900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>157</td>\n",
              "      <td>1.025400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>158</td>\n",
              "      <td>0.735800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>159</td>\n",
              "      <td>0.498800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.371400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>161</td>\n",
              "      <td>0.493400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>162</td>\n",
              "      <td>1.047300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>163</td>\n",
              "      <td>1.050700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>164</td>\n",
              "      <td>1.031800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>0.815600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>166</td>\n",
              "      <td>1.055200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>167</td>\n",
              "      <td>2.277600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>168</td>\n",
              "      <td>1.162300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>169</td>\n",
              "      <td>0.760500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.570600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>171</td>\n",
              "      <td>0.665100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>172</td>\n",
              "      <td>0.567200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>173</td>\n",
              "      <td>1.138100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>174</td>\n",
              "      <td>0.441700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>0.911400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>176</td>\n",
              "      <td>0.248100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>177</td>\n",
              "      <td>0.667400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>178</td>\n",
              "      <td>0.904900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>179</td>\n",
              "      <td>0.802800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.460000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>181</td>\n",
              "      <td>0.543200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>182</td>\n",
              "      <td>0.162200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>183</td>\n",
              "      <td>1.068700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>184</td>\n",
              "      <td>0.748700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>185</td>\n",
              "      <td>1.588000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>0.624600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>187</td>\n",
              "      <td>0.955900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>188</td>\n",
              "      <td>0.655600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>189</td>\n",
              "      <td>0.999900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.836600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>191</td>\n",
              "      <td>0.388000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192</td>\n",
              "      <td>0.462500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>193</td>\n",
              "      <td>0.275700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>194</td>\n",
              "      <td>0.120700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>0.780700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>196</td>\n",
              "      <td>0.465200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>197</td>\n",
              "      <td>0.532000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>198</td>\n",
              "      <td>0.530400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>199</td>\n",
              "      <td>0.395400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.664100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>201</td>\n",
              "      <td>1.239400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>202</td>\n",
              "      <td>0.642500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>203</td>\n",
              "      <td>0.877300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>204</td>\n",
              "      <td>0.333500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>205</td>\n",
              "      <td>1.735900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>206</td>\n",
              "      <td>0.542900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>207</td>\n",
              "      <td>0.615000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>208</td>\n",
              "      <td>0.735400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>209</td>\n",
              "      <td>0.616800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.379800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>211</td>\n",
              "      <td>0.677700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>212</td>\n",
              "      <td>0.652400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>213</td>\n",
              "      <td>0.207000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>214</td>\n",
              "      <td>0.031500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>215</td>\n",
              "      <td>0.698000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>216</td>\n",
              "      <td>0.844300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>217</td>\n",
              "      <td>0.578900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>218</td>\n",
              "      <td>0.143000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>219</td>\n",
              "      <td>0.944600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.348800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>221</td>\n",
              "      <td>0.234400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>222</td>\n",
              "      <td>0.962500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>223</td>\n",
              "      <td>0.284100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>224</td>\n",
              "      <td>1.442700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>0.699900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>226</td>\n",
              "      <td>0.311300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>227</td>\n",
              "      <td>0.104900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>228</td>\n",
              "      <td>0.992500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>229</td>\n",
              "      <td>0.489400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.303200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>231</td>\n",
              "      <td>0.683200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>232</td>\n",
              "      <td>0.836200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>233</td>\n",
              "      <td>1.068300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>0.553800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>235</td>\n",
              "      <td>1.329100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>236</td>\n",
              "      <td>0.371900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>237</td>\n",
              "      <td>0.504000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>238</td>\n",
              "      <td>0.864300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>239</td>\n",
              "      <td>0.510100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.698400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>241</td>\n",
              "      <td>0.459900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>242</td>\n",
              "      <td>0.492900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>243</td>\n",
              "      <td>0.667300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>244</td>\n",
              "      <td>0.227800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>245</td>\n",
              "      <td>0.228300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>246</td>\n",
              "      <td>0.649600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>247</td>\n",
              "      <td>0.217200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>248</td>\n",
              "      <td>0.537100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>249</td>\n",
              "      <td>0.562600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.431900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>251</td>\n",
              "      <td>1.048500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>252</td>\n",
              "      <td>0.177100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>253</td>\n",
              "      <td>0.289900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>254</td>\n",
              "      <td>0.797400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>255</td>\n",
              "      <td>0.517800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>256</td>\n",
              "      <td>0.540300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>257</td>\n",
              "      <td>0.640000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>258</td>\n",
              "      <td>0.499400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>259</td>\n",
              "      <td>0.911600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.277500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>261</td>\n",
              "      <td>0.128800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>262</td>\n",
              "      <td>0.491500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>263</td>\n",
              "      <td>0.125000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>264</td>\n",
              "      <td>0.625100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>265</td>\n",
              "      <td>0.140700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>266</td>\n",
              "      <td>0.824700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>267</td>\n",
              "      <td>0.897500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>268</td>\n",
              "      <td>0.372400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>269</td>\n",
              "      <td>0.630800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.306300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>271</td>\n",
              "      <td>0.244500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>272</td>\n",
              "      <td>0.063400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>273</td>\n",
              "      <td>0.712900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>274</td>\n",
              "      <td>0.480600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>0.502400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>276</td>\n",
              "      <td>0.098600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>277</td>\n",
              "      <td>0.475500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>278</td>\n",
              "      <td>0.716400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>279</td>\n",
              "      <td>0.167100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.602000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>281</td>\n",
              "      <td>1.265400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>282</td>\n",
              "      <td>0.974600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>283</td>\n",
              "      <td>0.688000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>284</td>\n",
              "      <td>0.480100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>285</td>\n",
              "      <td>0.142700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>286</td>\n",
              "      <td>0.547000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>287</td>\n",
              "      <td>0.081300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>288</td>\n",
              "      <td>0.595000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>289</td>\n",
              "      <td>0.658500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.245500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>291</td>\n",
              "      <td>0.636000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>292</td>\n",
              "      <td>0.390000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>293</td>\n",
              "      <td>0.402300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>294</td>\n",
              "      <td>0.426400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>295</td>\n",
              "      <td>0.462900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>296</td>\n",
              "      <td>0.662400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>297</td>\n",
              "      <td>0.538100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>298</td>\n",
              "      <td>0.221200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>299</td>\n",
              "      <td>0.441400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.300900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=18 < factor=28, reset height=factor\n",
            "smart_resize: height=18 < factor=28, reset height=factor\n",
            "smart_resize: height=14 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=18 < factor=28, reset height=factor\n",
            "smart_resize: height=17 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=17 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=16 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=16 < factor=28, reset height=factor\n",
            "smart_resize: height=18 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=17 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=13 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=17 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=20 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=16 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=18 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=17 < factor=28, reset height=factor\n",
            "smart_resize: height=15 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=13 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=17 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=16 < factor=28, reset height=factor\n",
            "smart_resize: height=17 < factor=28, reset height=factor\n",
            "smart_resize: height=16 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=17 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=17 < factor=28, reset height=factor\n",
            "smart_resize: height=17 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=17 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=14 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=18 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=20 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=18 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=18 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=20 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=15 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=15 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=17 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=17 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=13 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=20 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=20 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=18 < factor=28, reset height=factor\n",
            "smart_resize: height=16 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=17 < factor=28, reset height=factor\n",
            "smart_resize: height=20 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=17 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=18 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=18 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=15 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=15 < factor=28, reset height=factor\n",
            "smart_resize: height=18 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=16 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=16 < factor=28, reset height=factor\n",
            "smart_resize: height=20 < factor=28, reset height=factor\n",
            "smart_resize: height=13 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=14 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=20 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=15 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=18 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=17 < factor=28, reset height=factor\n",
            "smart_resize: height=20 < factor=28, reset height=factor\n",
            "smart_resize: height=20 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=14 < factor=28, reset height=factor\n",
            "smart_resize: height=14 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=16 < factor=28, reset height=factor\n",
            "smart_resize: height=16 < factor=28, reset height=factor\n",
            "smart_resize: height=12 < factor=28, reset height=factor\n",
            "smart_resize: height=15 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=18 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=20 < factor=28, reset height=factor\n",
            "smart_resize: height=14 < factor=28, reset height=factor\n",
            "smart_resize: height=20 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=20 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=16 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=16 < factor=28, reset height=factor\n",
            "smart_resize: height=12 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=17 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=17 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=15 < factor=28, reset height=factor\n",
            "smart_resize: height=15 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=14 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=13 < factor=28, reset height=factor\n",
            "smart_resize: height=17 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=20 < factor=28, reset height=factor\n",
            "smart_resize: height=15 < factor=28, reset height=factor\n",
            "smart_resize: height=14 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=18 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=20 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=20 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=15 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=18 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=13 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=14 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=17 < factor=28, reset height=factor\n",
            "smart_resize: height=16 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=16 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=18 < factor=28, reset height=factor\n",
            "smart_resize: height=20 < factor=28, reset height=factor\n",
            "smart_resize: height=20 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=18 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=15 < factor=28, reset height=factor\n",
            "smart_resize: height=16 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=15 < factor=28, reset height=factor\n",
            "smart_resize: height=14 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=16 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=20 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=23 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=20 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=27 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=26 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=25 < factor=28, reset height=factor\n",
            "smart_resize: height=19 < factor=28, reset height=factor\n",
            "smart_resize: height=21 < factor=28, reset height=factor\n",
            "smart_resize: height=15 < factor=28, reset height=factor\n",
            "smart_resize: height=24 < factor=28, reset height=factor\n",
            "smart_resize: height=14 < factor=28, reset height=factor\n",
            "smart_resize: height=22 < factor=28, reset height=factor\n"
          ]
        }
      ],
      "source": [
        "trainer_stats = trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "cellView": "form",
        "id": "pCqnaKmlO1U9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a1c2288-619a-4f8f-a522-863682536bf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2012.9737 seconds used for training.\n",
            "33.55 minutes used for training.\n",
            "Peak reserved memory = 12.635 GB.\n",
            "Peak reserved memory for training = 7.369 GB.\n",
            "Peak reserved memory % of max memory = 85.713 %.\n",
            "Peak reserved memory for training % of max memory = 49.99 %.\n"
          ]
        }
      ],
      "source": [
        "# @title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory / max_memory * 100, 3)\n",
        "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(\n",
        "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
        ")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekOmTR1hSNcr"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Let's run the model! You can change the instruction and input - leave the output blank!\n",
        "\n",
        "We use `min_p = 0.1` and `temperature = 1.5`. Read this [Tweet](https://x.com/menhguin/status/1826132708508213629) for more information on why."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "from jiwer import cer\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. Setup Selection\n",
        "num_samples = 10\n",
        "if len(train_dataset) < num_samples:\n",
        "    num_samples = len(train_dataset)\n",
        "\n",
        "indices = random.sample(range(len(train_dataset)), num_samples)\n",
        "\n",
        "predictions = []\n",
        "references = []\n",
        "\n",
        "print(f\"Starting inference on {num_samples} random samples...\")\n",
        "\n",
        "# 2. Loop through samples\n",
        "for idx in tqdm(indices):\n",
        "    image = train_dataset[idx][\"images\"][0]\n",
        "    ground_truth = train_dataset[idx][\"messages\"][1][\"content\"][0][\"text\"]\n",
        "    instruction = \"OCR:\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": [\n",
        "            {\"type\": \"image\"},\n",
        "            {\"type\": \"text\", \"text\": instruction}\n",
        "        ]}\n",
        "    ]\n",
        "\n",
        "    text_prompt = processor.tokenizer.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    inputs = processor(\n",
        "        image, text_prompt, add_special_tokens=False, return_tensors=\"pt\"\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    # Generate\n",
        "    with torch.inference_mode():\n",
        "        output_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=128,\n",
        "            use_cache=False,  # <--- CHANGED THIS TO FALSE\n",
        "            temperature=1.5,\n",
        "            min_p=0.1\n",
        "        )\n",
        "\n",
        "    # Decode Output\n",
        "    input_length = inputs.input_ids.shape[1]\n",
        "    generated_ids = output_ids[:, input_length:]\n",
        "    pred_text = processor.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    predictions.append(pred_text)\n",
        "    references.append(ground_truth)\n",
        "\n",
        "# 3. Calculate CER\n",
        "score = cer(references, predictions)\n",
        "print(f\"\\nResults over {num_samples} samples:\")\n",
        "print(f\"Average CER: {score:.4f} (Lower is better)\")\n",
        "print(f\"Percentage Accuracy: {(1-score)*100:.2f}%\")"
      ],
      "metadata": {
        "id": "fpwhtfsSnENd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f170aeca-ffd4-43b9-8d86-6143164277b0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting inference on 10 random samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:04<00:00,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results over 10 samples:\n",
            "Average CER: 0.1017 (Lower is better)\n",
            "Percentage Accuracy: 89.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMuVrWbjAzhc"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving, loading finetuned models\n",
        "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
        "\n",
        "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "upcOlWe7A1vc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a4975a1-6f9b-4dcb-f76c-1a189ecbdd7e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('lora_model_v2/tokenizer_config.json',\n",
              " 'lora_model_v2/special_tokens_map.json',\n",
              " 'lora_model_v2/chat_template.jinja',\n",
              " 'lora_model_v2/tokenizer.model',\n",
              " 'lora_model_v2/added_tokens.json',\n",
              " 'lora_model_v2/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "model.save_pretrained(\"lora_model_v2\")  # Local saving\n",
        "tokenizer.save_pretrained(\"lora_model_v2\")\n",
        "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
        "# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEEcJ4qfC7Lp"
      },
      "source": [
        "Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MKX_XKs_BNZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a77f3321-7b88-4504-e382-e2b37314cf7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Delfu</s>\n"
          ]
        }
      ],
      "source": [
        "if False:\n",
        "    from unsloth import FastVisionModel\n",
        "    model, tokenizer = FastVisionModel.from_pretrained(\n",
        "        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        load_in_4bit = False, # Set to False for 16bit LoRA\n",
        "    )\n",
        "    FastVisionModel.for_inference(model) # Enable for inference!\n",
        "\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens=128,\n",
        "                   use_cache=False, temperature=1.5, min_p=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f422JgM9sdVT"
      },
      "source": [
        "### Saving to float16 for VLLM\n",
        "\n",
        "We also support saving to `float16` directly. Select `merged_16bit` for float16. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "iHjt_SMYsd3P"
      },
      "outputs": [],
      "source": [
        "# Select ONLY 1 to save! (Both not needed!)\n",
        "\n",
        "# Save locally to 16bit\n",
        "if False: model.save_pretrained_merged(\"unsloth_finetune\", tokenizer,)\n",
        "\n",
        "# To export and save to your Hugging Face account\n",
        "if False: model.push_to_hub_merged(\"YOUR_USERNAME/unsloth_finetune\", tokenizer, token = \"PUT_HERE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORCxqLRwY0EZ"
      },
      "source": [
        "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/unsloth) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
        "\n",
        "Some other links:\n",
        "1. Train your own reasoning model - Llama GRPO notebook [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-GRPO.ipynb)\n",
        "2. Saving finetunes to Ollama. [Free notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)\n",
        "3. Llama 3.2 Vision finetuning - Radiography use case. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb)\n",
        "6. See notebooks for DPO, ORPO, Continued pretraining, conversational finetuning and more on our [documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks)!\n",
        "\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://unsloth.ai\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "  <a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
        "  <a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a>\n",
        "\n",
        "  Join Discord if you need help + ‚≠êÔ∏è <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠êÔ∏è\n",
        "\n",
        "  This notebook and all Unsloth notebooks are licensed [LGPL-3.0](https://github.com/unslothai/notebooks?tab=LGPL-3.0-1-ov-file#readme)\n",
        "</div>\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
